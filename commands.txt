Start the Docker
docker run -e DISPLAY=$DISPLAY -v /home/achulawa/rl_viewplanning:/home/dir -it --gpus all --rm --name rlviewplanning-container --network=host rlviewplanning-img

Start training an agent in the CartPole-v1 environment
python train.py --algo ppo --env CartPole-v1 --tensorboard-log /home/dir/RL_CoveragePlanning/tensorboard/CartPoleV1 -P

Start tensorboard for Cartpole Results 
tensorboard --logdir=/home/dir/RL_CoveragePlanning/tensorboard/CartPoleV1

Start Training in Coverage environment
python train.py --tensorboard-log /home/dir/RL_CoveragePlanning/tensorboard/CoverageEnv-v0 -P